---
title: What is Sampling Variation?
author: Bas Machielsen
date: '2024-10-07'
slug: []
categories: []
tags: []
---

## What is Sampling Variation?

### Introduction

In this blog post, I want to pay attention to the concept of **sampling variation**. In my econometrics classes, I have often found that students have a hard time wrapping their heads around this concept, especially in the case of regression analysis. Some of the questions I often get range from "why is our estimate of $\beta$ uncertain, since we have obtained it in a deterministic way from our data sample" to "where do $t$ statistics come from?". 

In this blog post, I explain the fundamental concept responsible for why our estimate of $\beta$ is uncertain, and how to characterize (meaning, put probabilities on it) this uncertainty: the concept of **sampling variation**. In this characterization, we'll also focus on the origins of the $t$ distribution used for hypothesis testing. 

Be that as it may, the basic concept of sampling variation is very easy to grasp. 

Consider a series of i.i.d. normally distributed random variables $X_i$ (indexed by the $i$'th observation), distributed with mean $\mu$ and variance $\sigma^2$. This means that we pretend that all of our data points are generated by such a normal distribution, and each observation in our dataset is generated by that very same distribution, irrespective of preceding or subsequent data points. 

As an econometrician, it's your job to estimate the $\mu$ and $\sigma^2$ parameters of that normal distribution based on a finite sample of $N$ observations. The following piece of R code illustrates that:

```{r, message=FALSE}
# Load libraries, set seed for reproducability
library(tidyverse, quietly = TRUE)
set.seed(1234)

# Set parameters for our normal distribution and sample size
mu <- 5; sigma_sq <- 1; n <- 20

# Sample from this "true" population distribution
sample <- tibble(data=rnorm(n=n, mean=mu, sd=sqrt(sigma_sq)))

head(sample, 5)

mean(sample$data)
```

As you can see, we have sampled from a normal distribution with $\mu=5$. However, our estimated mean is only `r mean(sample$data)`.

Because you have only twenty data points, the probability of you getting _exactly_ 5 as an estimate for your $\mu$ is very small (in fact, it's zero). In addition, there is a certain probability of you sampling _exclusively_ very high-valued data points and your estimated mean being way higher than five. Similarly, there is a certain probability of sampling low-valued data points, making your estimated mean way lower than five.

All of this can happen precisely due to **coincidence**. The process of putting certain numbers on these probabilities is the process of deriving the **sampling distribution**. After we have found the sampling distribution, we can use it to quantify the uncertainty that we attach to a certain estimate. 

One particular parameter governing the sampling distribution is the sample size $N$. It turns out, as we will see, that the larger the sample size, the lower the probability of sampling _only_ extreme data points. 

If you don't understand this, consider repeated fair coin flips. The probability of receiving 3 out of 3 heads (a sample size of 3) is larger than the probability of receiving 10 out of 10 heads (a sample size of 10). Which in turn is smaller than the probability of receiving 100 out of 100 heads. Et cetera. 

Similarly, if our true normal distribution has $\mu=5$, the probability of, for example, observing only observations that are higher than, say, 6, becomes smaller and smaller as our sample size increases. 

Technically, the probability of drawing an observation _greater than 6_ from our normal random variable $\mathcal{N}(5, 1)$ is:

```{r}
p_greater_than_6 <- 1 - pnorm(6, mean=mu, sd = sqrt(sigma_sq))
```

So about 15%. The probability that two observations are both greater than six is:

```{r}
p_greater_than_6^2
```

So only 2%, because our observations are **independently distributed**. 

Because the probability of sampling only extreme observations decreases with the sample size, this means that, if your sample is very large, you're bound the end up with an estimate of $\mu$ that is fairly close to the real population parameter. 

Let us now derive more explicitly the sampling distribution of the around the parameter $\mu$. 

We know that we estimate the mean by:

$$
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i
$$

We also know that each $X_i$ has expected value equal to the population mean $\mathbb{E}[X_i]=\mu$ and variance $\sigma^2$. 

Let us now consider the sum of independent normal variables Let's call that $S$ for a second:

$$
S = \sum_{i=1}^N X_i
$$

We know that the $S$ is also normally distributed as it is a combination of i.i.d. normal distributions, and let us now derive the $\mu$ and the $\sigma^2$ of the $S$, that is, of the normal distribution that arises from the sum of $N$ i.i.d. normal random variables. 

Since all of the $N$ i.i.d. normals have the same expectation, $\mu$, $S$ will have the expected value $N \mu$. Since all of them are independent, and have the same variance, the variance of the $S$ will equal $N \sigma^2$. 

Since the sample mean $\bar{X}$ is just the sum divided by $\frac{1}{N}$, the sample mean $\bar{X}$ will also follow a normal distribution. The $\mu$ of that distribution, denoted as $\mu_{bar{X}} is just:

$$
\mu_{\bar{X}} = \frac{1}{N} \mu_S
$$

where $\mu_S$ is the mean of $S$, which we have seen to equal $N \mu$. Hence, the expected value of the sample mean $\bar{X}$ is $\mu$. That is a good thing! This means that the sample mean is an unbiased estimator of the population mean. 

As for the variance, remember the rule that: $\text{Var}(aZ)= a^2 \text{Var}(Z)$ for any random variable $Z$. In this case, the variance of $\bar{X} = \text{Var}(\frac{1}{N} \text{Var}(S))$. 

This equals:

$$
\sigma^2_{\bar{X}} = \frac{1}{N^2} \text{Var}(S) = \frac{1}{N^2} N \sigma^2 = \frac{1}{N} \sigma^2
$$


Hence, what we have derived is that the _sample mean_ is distributed as:

$$
\bar{X} \sim \mathcal{N}(\mu, \frac{1}{N} \sigma^2)
$$

This is very nice. That means that as the sample size grows, we're obtaining a distribution around the population mean with a smaller and smaller variance. This formally illustrates what I argued anecdotally earlier: the probability of estimating an extreme sample mean (in the sense of being far away from the population mean) decreases with $N$. 

Now that we know how to do this in a simple case, we can also do the exact same thing in the context of linear regression analysis. 

### Sampling Variation in the Context of Regression Analysis

In linear regression analysis, we often start with a linear model: 

$$
Y = X \beta + \epsilon
$$

Note that the only source of random variation here is the $\epsilon$. If $Y=X\beta$ (without $\epsilon$) we would always recover our $\beta$ coefficient with certainty. But because of $\epsilon$ can take on certain values, purely due to coincidence, in our sample, this could skew our estimate of $\beta$, potentially far away from the true $\beta$. Let me illustrate that with a piece of R code as well:

```{r, message=F, warning=FALSE}
# Load regression libraries
library(fixest, quietly = TRUE); library(modelsummary)

# Set the parameters
epsilon <- rnorm(n=50, mean=0, sd=2)
beta <- 3
x <- runif(n=50, min=0, max=5)

# Generate Y as a function of X and Epsilon
y <- x*beta + epsilon

# Create a data.frame and plot the data points
df <- tibble(x=x, y=y)

# Plot
ggplot(df, aes(x=x, y=y)) + geom_point()

# Estimate a linear model
feols(y ~ x, data = df) |>
  modelsummary(gof_map = "nobs")
```

As you can see, our coefficient estimate is $3.17$ and not 3, purely due to coincidence in sampling. Hence, our $\beta$ coefficient also exhibits sampling variation as a result of the randomness in the error term $\epsilon$. 

To illustrate that even more clearly, let me repeat the preceding piece of code 1,000 times. That is:

- Sample $N=50$ observations from $\epsilon$ and $X$. 
- Generate $Y$ from these observations
- Estimate the $\beta$ coefficient.

And finally, plot the resulting $1,000 \beta$ coefficients. 

```{r}
coefficients <- map_dbl(1:1000, ~ {
  epsilon <- rnorm(n=50, mean=0, sd=2)
  x <- runif(n=50, min=0, max=5)
  y <- x*beta + epsilon # Remember, true beta is still 3
  df <- tibble(x=x, y=y)
  reg <- feols(y ~ x, data = df)
  estimated_beta <- reg$coeftable$Estimate[2]
  
  return(estimated_beta)
})

# Plot the result
tibble(coef=coefficients) |>
  ggplot(aes(x=coef)) + geom_histogram()
```

Even though on average, we estimate a $\beta$ coefficient of 3, but out of these 1,000 times, we have, purely due to coincidental values of our $\epsilon$ obtained $\beta$ coefficients that are quite different from 3. 

Under the assumption that our error term is normally distribution with mean 0 and variance $\sigma^2$, we can also derive the sampling distribution for our $\beta$ coefficients. 


### Hypothesis Testing?

So what are we doing when we're doing hypothesis testing? 




### Conclusion

This blog post focused on the concept of sampling variation. In a very simple case, we introduced the concept by looking at a series of $N$ i.i.d. normal variables, and derived the uncertainty surrounding our estimated mean. 

Then, we did the same thing for linear regression, which turned out to be a little bit more difficult. The difficulty was that we don't have access to the error variance parameter $\sigma^2$, but have to make do with an estimate of that parameter. That makes it that the final sampling distribution we end up with is not normal, but $t$ distributed. 

Finally, we focused on hypothesis testing. In hypothesis testing, we hold that the true coefficient estimate is a certain number, for example, 0. Then, we use our obtained information on the sampling distribution to consider how likely it is that our _actual_ coefficient has been obtained given that the true coefficient is zero, and the sampling distribution is the distribution we've estimated.

Hopefully, this background article has helped you visualizing and seeing more clearly how sampling variation, and its conceptual sibling, hypothesis testing, work. Thanks for reading! If you have any comments, mail them to a dot h dot machielsen at uu dot nl. 
